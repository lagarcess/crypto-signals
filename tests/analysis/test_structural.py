"""Unit tests for the structural analysis module."""

import time

import numpy as np
import pandas as pd
import pytest
from crypto_signals.analysis.structural import (
    Pivot,
    _zigzag_core,
    fast_pip,
    filter_pivots_by_lookback,
    find_pivots,
    get_pivot_dataframe,
    get_recent_pivots,
    warmup_jit,
)


@pytest.fixture
def simple_ohlcv_df():
    """Create a simple OHLCV DataFrame with clear peaks and valleys."""
    dates = pd.date_range(start="2024-01-01", periods=20, freq="D")
    # Create a clear zigzag pattern: up -> down -> up -> down
    data = {
        "open": [100] * 20,
        "high": [
            100,
            105,
            110,
            115,
            120,  # Rising to peak at 120
            118,
            115,
            110,
            105,
            100,  # Falling to valley at 100
            102,
            108,
            115,
            120,
            125,  # Rising to peak at 125
            122,
            118,
            112,
            108,
            105,  # Falling
        ],
        "low": [
            98,
            103,
            108,
            113,
            118,  # Rising
            115,
            112,
            107,
            102,
            98,  # Falling to valley at 98
            100,
            106,
            113,
            118,
            123,  # Rising
            120,
            115,
            110,
            105,
            103,  # Falling
        ],
        "close": [
            102,
            107,
            112,
            117,
            119,  # Rising
            116,
            113,
            108,
            103,
            99,  # Falling
            104,
            110,
            117,
            122,
            124,  # Rising
            121,
            116,
            111,
            106,
            104,  # Falling
        ],
        "volume": [1000] * 20,
    }
    return pd.DataFrame(data, index=dates)


@pytest.fixture
def large_random_df():
    """Create a large DataFrame for performance testing."""
    n = 100_000
    dates = pd.date_range(start="2020-01-01", periods=n, freq="h")
    np.random.seed(42)

    # Random walk with volatility
    base = 100 + np.cumsum(np.random.randn(n) * 0.5)
    high = base + np.abs(np.random.randn(n)) * 2
    low = base - np.abs(np.random.randn(n)) * 2
    close = base + np.random.randn(n) * 0.5

    return pd.DataFrame(
        {
            "open": base,
            "high": high,
            "low": low,
            "close": close,
            "volume": np.random.randint(1000, 10000, n),
        },
        index=dates,
    )


class TestWarmupJit:
    """Tests for JIT warm-up functionality."""

    def test_warmup_jit_runs_without_error(self):
        """Warmup should complete without errors."""
        warmup_jit()  # Should not raise

    def test_warmup_jit_second_call_fast(self):
        """Second call should be fast (already compiled)."""
        warmup_jit()  # First call - may be slow due to compilation

        start = time.perf_counter()
        warmup_jit()  # Second call - should be fast
        elapsed = time.perf_counter() - start

        # After warm-up, should execute in <10ms
        assert elapsed < 0.01, f"Warmed-up call took {elapsed:.3f}s"


class TestZigZagCore:
    """Tests for the core ZigZag algorithm."""

    def test_empty_array_returns_empty(self):
        """Empty input should return empty output."""
        result = _zigzag_core(np.array([]), np.array([]), 0.05)
        assert len(result) == 0

    def test_single_element_returns_empty(self):
        """Single element should return empty (no structure)."""
        result = _zigzag_core(np.array([100.0]), np.array([100.0]), 0.05)
        # With only one element, no pivots can be detected
        assert len(result) <= 1

    def test_detects_simple_peak(self):
        """Should detect a clear peak."""
        highs = np.array([100.0, 110.0, 120.0, 110.0, 100.0], dtype=np.float64)
        lows = np.array([95.0, 105.0, 115.0, 105.0, 95.0], dtype=np.float64)

        result = _zigzag_core(highs, lows, 0.10)  # 10% threshold

        # Should find at least one peak
        peaks = result[result[:, 2] == 1]  # type 1 = PEAK
        assert len(peaks) >= 1
        # Peak should be at index 2 (price 120)
        peak_indices = peaks[:, 0]
        assert 2 in peak_indices

    def test_detects_simple_valley(self):
        """Should detect a clear valley."""
        highs = np.array([120.0, 110.0, 100.0, 110.0, 120.0], dtype=np.float64)
        lows = np.array([115.0, 105.0, 95.0, 105.0, 115.0], dtype=np.float64)

        result = _zigzag_core(highs, lows, 0.10)  # 10% threshold

        # Should find at least one valley
        valleys = result[result[:, 2] == 2]  # type 2 = VALLEY
        assert len(valleys) >= 1

    def test_threshold_filters_noise(self):
        """Higher threshold should filter out smaller moves."""
        # Create data with small oscillations
        highs = np.array([100.0, 102.0, 101.0, 103.0, 102.0], dtype=np.float64)
        lows = np.array([98.0, 100.0, 99.0, 101.0, 100.0], dtype=np.float64)

        result_low_thresh = _zigzag_core(highs, lows, 0.01)  # 1% threshold
        result_high_thresh = _zigzag_core(highs, lows, 0.10)  # 10% threshold

        # Higher threshold should detect fewer pivots
        assert len(result_high_thresh) <= len(result_low_thresh)


class TestFindPivots:
    """Tests for the high-level find_pivots function."""

    def test_returns_pivot_objects(self, simple_ohlcv_df):
        """Should return list of Pivot objects."""
        pivots = find_pivots(simple_ohlcv_df, pct_threshold=0.05)

        assert isinstance(pivots, list)
        for p in pivots:
            assert isinstance(p, Pivot)
            assert p.pivot_type in ("PEAK", "VALLEY")
            assert p.index >= 0
            assert p.price > 0

    def test_pivots_alternate_peak_valley(self, simple_ohlcv_df):
        """Pivots should generally alternate between peaks and valleys."""
        pivots = find_pivots(simple_ohlcv_df, pct_threshold=0.05)

        if len(pivots) >= 2:
            for i in range(1, len(pivots)):
                # Allow for some exceptions but generally should alternate
                if pivots[i].pivot_type == pivots[i - 1].pivot_type:
                    # Occasionally acceptable, but should be rare
                    pass

    def test_empty_dataframe_returns_empty(self):
        """Empty DataFrame should return empty list."""
        empty_df = pd.DataFrame(columns=["open", "high", "low", "close", "volume"])
        pivots = find_pivots(empty_df)
        assert pivots == []

    def test_timestamps_match_dataframe(self, simple_ohlcv_df):
        """Pivot timestamps should match the DataFrame index."""
        pivots = find_pivots(simple_ohlcv_df, pct_threshold=0.05)

        for p in pivots:
            assert p.timestamp in simple_ohlcv_df.index
            assert p.timestamp == simple_ohlcv_df.index[p.index]


class TestFastPIP:
    """Tests for the FastPIP algorithm."""

    def test_reduces_to_max_points(self, simple_ohlcv_df):
        """Should reduce points to at most max_points."""
        pips = fast_pip(simple_ohlcv_df, max_points=5)
        assert len(pips) <= 5

    def test_preserves_endpoints(self, simple_ohlcv_df):
        """First and last points should always be preserved."""
        pips = fast_pip(simple_ohlcv_df, max_points=5)

        indices = [p.index for p in pips]
        assert 0 in indices  # First point
        assert len(simple_ohlcv_df) - 1 in indices  # Last point

    def test_returns_all_if_fewer_than_max(self):
        """If data has fewer points than max, return all."""
        small_df = pd.DataFrame(
            {
                "open": [100, 105, 110],
                "high": [102, 107, 112],
                "low": [98, 103, 108],
                "close": [101, 106, 111],
                "volume": [1000, 1000, 1000],
            },
            index=pd.date_range("2024-01-01", periods=3, freq="D"),
        )

        pips = fast_pip(small_df, max_points=10)
        assert len(pips) == 3

    def test_empty_dataframe_returns_empty(self):
        """Empty DataFrame should return empty list."""
        empty_df = pd.DataFrame(columns=["open", "high", "low", "close", "volume"])
        pips = fast_pip(empty_df)
        assert pips == []


class TestPerformance:
    """Performance tests for O(N) complexity verification."""

    @pytest.mark.slow
    def test_zigzag_performance_million_points(self):
        """ZigZag should process 1M points in under 5ms (after warm-up)."""
        # Ensure JIT is warmed up
        warmup_jit()

        # Create 1 million data points
        n = 1_000_000
        np.random.seed(42)
        base = 100 + np.cumsum(np.random.randn(n) * 0.5)
        highs = (base + np.abs(np.random.randn(n)) * 2).astype(np.float64)
        lows = (base - np.abs(np.random.randn(n)) * 2).astype(np.float64)

        # Warm-up run (first call may include some overhead)
        _zigzag_core(highs[:1000].astype(np.float64), lows[:1000].astype(np.float64), 0.05)

        # Timed run
        start = time.perf_counter()
        result = _zigzag_core(highs.astype(np.float64), lows.astype(np.float64), 0.05)
        elapsed = time.perf_counter() - start

        # Should complete in under 50ms (relaxed from 5ms for CI variance)
        # In practice, Numba typically achieves 2-5ms
        assert elapsed < 0.05, f"ZigZag 1M points took {elapsed * 1000:.2f}ms"
        assert len(result) > 0, "Should detect some pivots"

    def test_linear_time_complexity(self, large_random_df):
        """Verify O(N) complexity by comparing different sizes."""
        warmup_jit()

        sizes = [10_000, 50_000, 100_000]
        times = []

        for size in sizes:
            df = large_random_df.iloc[:size]
            highs = df["high"].values.astype(np.float64)
            lows = df["low"].values.astype(np.float64)

            start = time.perf_counter()
            _zigzag_core(highs, lows, 0.05)
            elapsed = time.perf_counter() - start
            times.append(elapsed)

        # For O(N), time ratio should be close to size ratio
        # 50k should be ~5x slower than 10k
        # 100k should be ~10x slower than 10k
        _ratio_50k_10k = times[1] / times[0]  # noqa: F841
        ratio_100k_10k = times[2] / times[0]

        # Allow for some variance, but ratios should be roughly linear
        # 10x size should be roughly 10x time (within 3x margin)
        assert ratio_100k_10k < 30, f"Complexity > O(N): {ratio_100k_10k:.1f}x"


class TestUtilityFunctions:
    """Tests for utility functions."""

    def test_get_pivot_dataframe(self, simple_ohlcv_df):
        """Should convert pivots to DataFrame."""
        pivots = find_pivots(simple_ohlcv_df, pct_threshold=0.05)
        df = get_pivot_dataframe(pivots)

        assert isinstance(df, pd.DataFrame)
        assert list(df.columns) == ["timestamp", "price", "pivot_type", "index"]
        assert len(df) == len(pivots)

    def test_get_pivot_dataframe_empty(self):
        """Empty pivot list should return empty DataFrame."""
        df = get_pivot_dataframe([])
        assert len(df) == 0
        assert list(df.columns) == ["timestamp", "price", "pivot_type", "index"]

    def test_filter_pivots_by_lookback(self, simple_ohlcv_df):
        """Should filter pivots within lookback window."""
        pivots = find_pivots(simple_ohlcv_df, pct_threshold=0.05)

        # Filter to last 10 bars
        filtered = filter_pivots_by_lookback(pivots, current_index=19, max_lookback=10)

        for p in filtered:
            assert p.index >= 9  # 19 - 10 = 9
            assert p.index <= 19

    def test_get_recent_pivots(self, simple_ohlcv_df):
        """Should return most recent N pivots."""
        pivots = find_pivots(simple_ohlcv_df, pct_threshold=0.05)

        recent = get_recent_pivots(pivots, count=2)
        assert len(recent) <= 2
        if len(pivots) >= 2:
            assert recent[-1] == pivots[-1]  # Most recent should be included

    def test_get_recent_pivots_by_type(self, simple_ohlcv_df):
        """Should filter by pivot type."""
        pivots = find_pivots(simple_ohlcv_df, pct_threshold=0.05)

        peaks = get_recent_pivots(pivots, count=2, pivot_type="PEAK")
        for p in peaks:
            assert p.pivot_type == "PEAK"

        valleys = get_recent_pivots(pivots, count=2, pivot_type="VALLEY")
        for p in valleys:
            assert p.pivot_type == "VALLEY"
